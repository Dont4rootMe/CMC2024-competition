{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SetUp решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Any\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numexpr\n",
    "import os\n",
    "\n",
    "# dl setup\n",
    "import sklearn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: ./cmc-ml-spotify-recommendations\n",
      "train_assigns: ./cmc-ml-spotify-recommendations/train.csv\n",
      "assign_info: ./cmc-ml-spotify-recommendations/added_info.csv\n",
      "audio_features: ./cmc-ml-spotify-recommendations/audio_features.csv\n",
      "track_info: ./cmc-ml-spotify-recommendations/tracks_info.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path_conf = OmegaConf.create({\n",
    "    'path': './cmc-ml-spotify-recommendations',\n",
    "    'train_assigns': '${concat_path:${path},\"train.csv\"}',\n",
    "    'assign_info': '${concat_path:${path},\"added_info.csv\"}',\n",
    "    'audio_features': '${concat_path:${path},\"audio_features.csv\"}',\n",
    "    'track_info': '${concat_path:${path},\"tracks_info.csv\"}',\n",
    "})\n",
    "\n",
    "print(OmegaConf.to_yaml(path_conf, resolve=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "OmegaConf.register_new_resolver('concat_path', lambda *joints: os.path.join(*joints), replace=True)\n",
    "\n",
    "conf = OmegaConf.create({\n",
    "    # path config\n",
    "    'path': {\n",
    "        'standard_path': './cmc-ml-spotify-recommendations',\n",
    "        'train_assigns': '${concat_path:${path.standard_path},\"train.csv\"}',\n",
    "        'assign_info': '${concat_path:${path.standard_path},\"added_info.csv\"}',\n",
    "        'audio_features': '${concat_path:${path.standard_path},\"audio_features.csv\"}',\n",
    "        'track_info': '${concat_path:${path.standard_path},\"tracks_info.csv\"}',\n",
    "    },\n",
    "\n",
    "    # parsing audio features\n",
    "    'audio_features_conf': {\n",
    "        'drop': ['key', 'time_signature'],\n",
    "        'normalize': ['danceability', 'energy', 'loudness', \n",
    "                    'speechiness', 'acousticness', 'instrumentalness', \n",
    "                    'liveness', 'valence', 'tempo', 'duration_ms'],\n",
    "    },\n",
    "\n",
    "    # parsing assignment info\n",
    "    'assignment_info_conf': {\n",
    "        'drop': ['added_by_type', 'added_by_id', 'playlist_id'],\n",
    "        'parse_time': True,\n",
    "    },\n",
    "\n",
    "    # parsing track info\n",
    "    'track_info_conf': {\n",
    "        'drop': ['track_artists', 'track_available_markets', 'track_name', 'track_type', 'track_album_album',\n",
    "                 'track_album_artists', 'track_album_id', 'track_album_name', 'track_album_type',\n",
    "                 'track_disc_number', 'track_track_number', 'track_album_disc_number', 'track_album_track_number'],\n",
    "        'bool': ['track_episode', 'track_explicit', 'track_is_local', 'track_track', 'track_album_episode', \n",
    "                 'track_album_explicit', 'track_album_is_local', 'track_album_track'],\n",
    "        'normalize': ['track_duration_ms', 'track_popularity', 'track_album_duration_ms', 'track_album_popularity'],\n",
    "        \n",
    "    },\n",
    "\n",
    "    # learning config\n",
    "    'learning': {\n",
    "        'dataloader': {\n",
    "            'split_seed': 666,\n",
    "            'n_workers': 4,\n",
    "            'train_test_split': [0.8, 0.2],\n",
    "            'batch_size': 512,\n",
    "        }\n",
    "\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeaturesDataset(Dataset):\n",
    "    def __init__(self, path, config):\n",
    "        self.df = pd.read_csv(path).drop(columns=config.drop)\n",
    "        self.normalize = StandardScaler(with_mean=True, with_std=True).set_output(transform='pandas')\n",
    "\n",
    "        for column in config.normalize:\n",
    "            self.df[column] = self.df[column].astype(np.float32)\n",
    "        \n",
    "        self.df.loc[:, config.normalize] = self.normalize.fit_transform(self.df.loc[:, config.normalize])\n",
    "        self.df['track_id'] = self.df['id']\n",
    "        self.df = self.df.drop(columns='id')\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Any:\n",
    "        return self.df[self.df['track_id'] == index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentInfoDataset(Dataset):\n",
    "    def __init__(self, path, config):\n",
    "        self.df = pd.read_csv(path).drop(columns=config.drop)\n",
    "        \n",
    "        if config.parse_time:\n",
    "            self.df['added_at'] = pd.to_datetime(self.df['added_at']).dt.tz_localize(None)\n",
    "            self.df['added_at'] = ((self.df['added_at'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')).astype(np.float32)\n",
    "\n",
    "            self.time_normalize = StandardScaler(with_mean=True, with_std=True).set_output(transform='pandas')\n",
    "            self.df['added_at'] = self.time_normalize.fit_transform((self.df[['added_at']]))\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Any:\n",
    "        return self.df[self.df['track_id'] == index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotifyTrackDataset(Dataset):\n",
    "    def __init__(self, path, config, audio_ds):        \n",
    "        data = pd.read_csv(path).drop(columns=config.drop)\n",
    "\n",
    "        for column in config.bool:\n",
    "            data[column] = data[column].astype(np.float32)\n",
    "        normalize = StandardScaler(with_mean=True, with_std=True).set_output(transform='pandas')\n",
    "        data.loc[:, config.normalize] = normalize.fit_transform(data.loc[:, config.normalize])\n",
    "\n",
    "        self.keys = {key: i for i, key in enumerate(data.track_id)}\n",
    "        self.data = data.merge(audio_ds.df, on='track_id', how='left').drop(columns=['track_id']).to_numpy()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Any:\n",
    "        return torch.tensor(self.data[self.keys[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dataset = AudioFeaturesDataset(conf.path.audio_features, conf.audio_features_conf)\n",
    "# assignment_info_dataset = AssignmentInfoDataset(conf.path.assign_info, conf.assignment_info_conf)\n",
    "spotify_dataset = SpotifyTrackDataset(conf.path.track_info, conf.track_info_conf, audio_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(conf.path.track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in test.track_id:\n",
    "   assert spotify_dataset['4E2TwkPZq7cYiTkYkmHMbz'].shape[0] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900411, 23)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899712"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(conf.learning.dataloader.split_seed)\n",
    "train_ds, test_ds = random_split(spotify_dataset, conf.learning.dataloader.train_test_split)\n",
    "train_dl = DataLoader(train_ds, batch_size=conf.learning.dataloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "81389",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[336], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MSU-competition-NTvN4v0h/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MSU-competition-NTvN4v0h/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MSU-competition-NTvN4v0h/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MSU-competition-NTvN4v0h/lib/python3.11/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MSU-competition-NTvN4v0h/lib/python3.11/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[333], line 17\u001b[0m, in \u001b[0;36mSpotifyTrackDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 81389"
     ]
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSU-competition",
   "language": "python",
   "name": "msu-competition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
